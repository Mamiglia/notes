[[Transformer State]]

[[Mathematical Framework for Transformer Circuits]]

[[Toy Models of Superposition]]

[Representation Learning](https://arxiv.org/abs/1206.5538)


[[Towards Monosemanticity]]

  

[Nanda's list of papers](https://www.alignmentforum.org/posts/NfFST5Mio7BCAQHPA/an-extremely-opinionated-annotated-list-of-my-favourite-1#comments)

> [!info] Sabotage evaluations for frontier models  
> A new paper on AI safety evaluations from Anthropic's Alignment Science team  
> [https://www.anthropic.com/research/sabotage-evaluations?ref=mail.bycloud.ai](https://www.anthropic.com/research/sabotage-evaluations?ref=mail.bycloud.ai)  

Clock and the Pizza

[https://arxiv.org/abs/2311.12092](https://arxiv.org/abs/2311.12092)

Chiedi di anomaly detection

  

  

  

  

  

  

  

- **OLD ideas**
    
    [[Bayesian Estimation of Fisher Matrix]]
    
    |**name**|**fields**|**pros**|**cons**|**impact**|
    |---|---|---|---|---|
    |Transformer State|representation engineering|completely novel approach to representation reading|needs to be validated on big LLMs|from none to foundational (based on how much information is actually encoded in the state)|
    |Bayes Fisher Information Matrix|machine unlearning, importance attribution|lightweight experiments, we can always just add more bayesian theory if things donâ€™t work out||incremental improvement on an already widespread technique|
    
    [[GFlowNet]]