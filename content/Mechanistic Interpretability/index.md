---
title: Mechanistic Interpretability
tags:
  - homepage
---
The idea we propose is this one: [[Transformer State]]. Here's a list of relevant papers:
- Introduction to representation learning: [[Mathematical Framework for Transformer Circuits]]
- Key concepts of superposition: [[Toy Models of Superposition]]
- One way of using internal representations: [Representation Learning](https://arxiv.org/abs/1206.5538)
- Introduction analysis on SAEs[[Towards Monosemanticity]]
	- New SAE architectures: [[Sparse Autoencoders]]

  

[Nanda's list of papers](https://www.alignmentforum.org/posts/NfFST5Mio7BCAQHPA/an-extremely-opinionated-annotated-list-of-my-favourite-1#comments)

> [!info] Sabotage evaluations for frontier models  
> A new paper on AI safety evaluations from Anthropic's Alignment Science team  
> [https://www.anthropic.com/research/sabotage-evaluations?ref=mail.bycloud.ai](https://www.anthropic.com/research/sabotage-evaluations?ref=mail.bycloud.ai)  

Clock and the Pizza

[https://arxiv.org/abs/2311.12092](https://arxiv.org/abs/2311.12092)

Chiedi di anomaly detection
